{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "147e98e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython in c:\\users\\sumathi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.1.46)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\sumathi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitpython) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\sumathi\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython) (5.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c7dc078a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder is not empty. Data might already be there.\n"
     ]
    }
   ],
   "source": [
    "import git\n",
    "import os\n",
    "\n",
    "# Updated to use C: drive which is safe and available\n",
    "repo_url = \"https://github.com/PhonePe/pulse.git\"\n",
    "destination_path = \"C:/Users/Sumathi/Documents/PhonePe_Pulse_Data\"\n",
    "\n",
    "# Create the folder automatically on your C: drive\n",
    "if not os.path.exists(destination_path):\n",
    "    os.makedirs(destination_path)\n",
    "    print(f\"Created folder at {destination_path}\")\n",
    "\n",
    "# Now try to clone\n",
    "try:\n",
    "    if len(os.listdir(destination_path)) == 0:\n",
    "        print(\"Starting clone... please wait.\")\n",
    "        git.Repo.clone_from(repo_url, destination_path)\n",
    "        print(\"Repository cloned successfully!\")\n",
    "    else:\n",
    "        print(\"Folder is not empty. Data might already be there.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df445e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b376e7eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My current location is: c:\\Users\\Sumathi\\pulse\n",
      "Does the folder exist? True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"My current location is:\", os.getcwd())\n",
    "print(\"Does the folder exist?\", os.path.exists(\"C:/Users/Sumathi/Documents/PhonePe_Pulse_Data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0c25e1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['andaman-&-nicobar-islands',\n",
       " 'andhra-pradesh',\n",
       " 'arunachal-pradesh',\n",
       " 'assam',\n",
       " 'bihar',\n",
       " 'chandigarh',\n",
       " 'chhattisgarh',\n",
       " 'dadra-&-nagar-haveli-&-daman-&-diu',\n",
       " 'delhi',\n",
       " 'goa',\n",
       " 'gujarat',\n",
       " 'haryana',\n",
       " 'himachal-pradesh',\n",
       " 'jammu-&-kashmir',\n",
       " 'jharkhand',\n",
       " 'karnataka',\n",
       " 'kerala',\n",
       " 'ladakh',\n",
       " 'lakshadweep',\n",
       " 'madhya-pradesh',\n",
       " 'maharashtra',\n",
       " 'manipur',\n",
       " 'meghalaya',\n",
       " 'mizoram',\n",
       " 'nagaland',\n",
       " 'odisha',\n",
       " 'puducherry',\n",
       " 'punjab',\n",
       " 'rajasthan',\n",
       " 'sikkim',\n",
       " 'tamil-nadu',\n",
       " 'telangana',\n",
       " 'tripura',\n",
       " 'uttar-pradesh',\n",
       " 'uttarakhand',\n",
       " 'west-bengal']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "path=r\"C:\\Users\\Sumathi\\pulse\\data\\aggregated\\transaction\\country\\india\\state\"\n",
    "Agg_state_list=os.listdir(path)\n",
    "Agg_state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4de55dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated Transaction:\n",
    "\n",
    "#Empty dictionary for collecting data\n",
    "storage_data={'State':[], 'Year':[], 'Quarter':[], 'Transaction_type':[], 'Transaction_count':[], 'Transaction_amount':[] }\n",
    "path=r\"C:\\Users\\Sumathi\\pulse\\data\\aggregated\\transaction\\country\\india\\state\"\n",
    "Agg_state_list=os.listdir(path)\n",
    "Agg_state_list\n",
    "\n",
    "for i in Agg_state_list:\n",
    "    p_i=os.path.join(path,i)    \n",
    "    Agg_yr=os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_yr:\n",
    "        p_j=os.path.join(p_i,j)\n",
    "        Agg_yr_list=os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_yr_list:\n",
    "            p_k=os.path.join(p_j,k)\n",
    "            with open(p_k,'r') as Data:\n",
    "                D=json.load(Data)\n",
    "                \n",
    "               \n",
    "\n",
    "            for z in D['data']['transactionData']:# z takes one transaction type \n",
    "                Name=z['name']\n",
    "                count=z['paymentInstruments'][0]['count']\n",
    "                amount=z['paymentInstruments'][0]['amount']\n",
    "                \n",
    "                storage_data['Transaction_type'].append(Name) \n",
    "                storage_data['Transaction_count'].append(count) \n",
    "                storage_data['Transaction_amount'].append(amount) \n",
    "                storage_data['State'].append(i) \n",
    "                storage_data['Year'].append(j)  \n",
    "                storage_data['Quarter'].append(int(k.strip('.json')))   \n",
    "\n",
    "Agg_Trans=pd.DataFrame(storage_data) \n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7e47b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5034, 6)\n"
     ]
    }
   ],
   "source": [
    "print(Agg_Trans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4b2fae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated insurance \n",
    "\n",
    "# empty Dictionary for Insurance:\n",
    "insurance_data = {'State': [], 'Year': [], 'Quarter': [], 'Transaction_Type': [], 'Transaction_Count': [], 'Transaction_Amount': []}\n",
    "\n",
    "path_ins = r\"C:\\Users\\Sumathi\\pulse\\data\\aggregated\\insurance\\country\\india\\state\"\n",
    "Agg_state_list_isurance = os.listdir(path_ins)\n",
    "\n",
    "for i in Agg_state_list_isurance:\n",
    "    p_i = os.path.join(path_ins, i)\n",
    "    Agg_year_isurance = os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_year_isurance:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        Agg_year_isurance_list = os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_year_isurance_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            with open(p_k, 'r') as Data:\n",
    "                D = json.load(Data)\n",
    "            \n",
    "            try:\n",
    "                # Correct: use transactionData instead of insuranceData\n",
    "                if D['data'] and 'transactionData' in D['data']:\n",
    "                    for z in D['data']['transactionData']:\n",
    "                            name= z['name'] \n",
    "                            count=z['paymentInstruments'][0]['count']\n",
    "                            amount=z['paymentInstruments'][0]['amount']\n",
    "                            insurance_data['Transaction_Type'].append(name)\n",
    "                            insurance_data['Transaction_Count'].append(count)\n",
    "                            insurance_data['Transaction_Amount'].append(amount)\n",
    "                            insurance_data['State'].append(i)\n",
    "                            insurance_data['Year'].append(j)\n",
    "                            insurance_data['Quarter'].append(int(k.strip('.json')))\n",
    "            \n",
    "            except (KeyError, TypeError):\n",
    "                # skip missing or null data\n",
    "                continue\n",
    "        \n",
    "Agg_Ins = pd.DataFrame(insurance_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7b200cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(682, 6)\n"
     ]
    }
   ],
   "source": [
    "print(Agg_Ins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d1bb4bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregated User:\n",
    "#empty Dictionary for User:\n",
    "user_data = {'State': [], 'Year': [], 'Quarter': [], 'Brand': [], 'User_Count': [], 'Percentage': [] ,'Registered_Users': [],\n",
    "    'App_Opens': []}\n",
    "\n",
    "path_user =  r\"C:\\Users\\Sumathi\\pulse\\data\\aggregated\\user\\country\\india\\state\"\n",
    "Agg_state_user_list=os.listdir(path_user)\n",
    "Agg_state_user_list\n",
    "\n",
    "for i in Agg_state_user_list:\n",
    "    p_i = os.path.join(path_user, i)\n",
    "    Agg_year_user=os.listdir(p_i)\n",
    "\n",
    "    for j in Agg_year_user:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        Agg_year_user_list=os.listdir(p_j)\n",
    "\n",
    "        for k in Agg_year_user_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            with open(p_k, 'r') as Data:\n",
    "                D = json.load(Data)\n",
    "\n",
    "           \n",
    "            try:\n",
    "                if D['data']['usersByDevice'] is not None:\n",
    "                    for z in D['data']['usersByDevice']:\n",
    "                        brand = z['brand']\n",
    "                        count = z['count']\n",
    "                        percentage = z['percentage']\n",
    "                        \n",
    "                        reg_users = D['data']['aggregated']['registeredUsers']\n",
    "                        app_opens = D['data']['aggregated']['appOpens']\n",
    "\n",
    "                        user_data['Brand'].append(z['brand'])\n",
    "                        user_data['User_Count'].append(z['count'])\n",
    "                        user_data['Percentage'].append(z['percentage'])\n",
    "                        user_data['Registered_Users'].append(reg_users)\n",
    "                        user_data['App_Opens'].append(app_opens)\n",
    "                        user_data['State'].append(i)\n",
    "                        user_data['Year'].append(j)\n",
    "                        user_data['Quarter'].append(int(k.strip('.json')))\n",
    "            except(KeyError,TypeError):\n",
    "                continue\n",
    "\n",
    "Agg_User = pd.DataFrame(user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "aaa6bdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6732, 8)\n"
     ]
    }
   ],
   "source": [
    "print(Agg_User.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cae4fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map Transaction :\n",
    "map_trans_data = {'State': [], 'Year': [], 'Quarter': [], 'District': [], 'Count': [], 'Amount': []}\n",
    "\n",
    "path_map_trans = r\"C:\\Users\\Sumathi\\pulse\\data\\map\\transaction\\hover\\country\\india\\state\"\n",
    "map_state_list = os.listdir(path_map_trans)\n",
    "\n",
    "for state in map_state_list:\n",
    "    p_i = os.path.join(path_map_trans, state)\n",
    "    years = os.listdir(p_i)\n",
    "    \n",
    "    for j in years:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        quarters = os.listdir(p_j)\n",
    "        \n",
    "        for k in quarters:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            with open(p_k, 'r') as f:\n",
    "                D = json.load(f)\n",
    "            \n",
    "        try:\n",
    "            if D['data']['hoverDataList'] is not None: \n",
    "             for district in D['data']['hoverDataList']:\n",
    "                \n",
    "                district_name = district['name']\n",
    "                count = district['metric'][0]['count']\n",
    "                amount = district['metric'][0]['amount']\n",
    "                \n",
    "                map_trans_data['State'].append(i)\n",
    "                map_trans_data['Year'].append(j)\n",
    "                map_trans_data['Quarter'].append(int(k.strip('.json')))\n",
    "                map_trans_data['District'].append(district_name)\n",
    "                map_trans_data['Count'].append(count)\n",
    "                map_trans_data['Amount'].append(amount)\n",
    "        except (KeyError, TypeError, IndexError):\n",
    "          continue  \n",
    "Map_Trans= pd.DataFrame(map_trans_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e0b980ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map insurance :\n",
    "map_ins_data = {'State': [], 'Year': [], 'Quarter': [], 'District': [], 'Insurance_Count': [], 'Insurance_Amount': []}\n",
    "\n",
    "path_map_ins = r\"C:\\Users\\Sumathi\\pulse\\data\\map\\insurance\\hover\\country\\india\\state\"\n",
    "map_ins_states = os.listdir(path_map_ins)\n",
    "\n",
    "for i in map_ins_states:\n",
    "    p_i = os.path.join(path_map_ins, i)\n",
    "    year_ins=os.listdir(p_i)\n",
    "\n",
    "    for j in  year_ins:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        quarter_ins=os.listdir(p_j)\n",
    "        \n",
    "        for k in quarter_ins:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            \n",
    "            with open(p_k, 'r') as Data:\n",
    "                D = json.load(Data)\n",
    "            try:\n",
    "                if D['data']['hoverDataList'] is not None:\n",
    "                  for z in D['data']['hoverDataList']:\n",
    "                                     \n",
    "                    dist_name = z['name']\n",
    "                    count = z['metric'][0]['count'] \n",
    "                    amount = z['metric'][0]['amount']\n",
    "                   \n",
    "                    map_ins_data['State'].append(i)\n",
    "                    map_ins_data['Year'].append(j)\n",
    "                    map_ins_data['Quarter'].append(int(k.strip('.json')))\n",
    "                    map_ins_data['District'].append(dist_name)\n",
    "                    map_ins_data['Insurance_Count'].append(count)\n",
    "                    map_ins_data['Insurance_Amount'].append(amount)\n",
    "                    \n",
    "            except (KeyError, TypeError, IndexError):\n",
    "                continue\n",
    "\n",
    "Map_Ins = pd.DataFrame(map_ins_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "40e7057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_user_data = {'State': [], 'Year': [], 'Quarter': [], \n",
    "    'District': [], 'Registered_Users': [], 'App_Opens': []}\n",
    "\n",
    "# 2. Define your base path\n",
    "path_map_user = r\"C:\\Users\\Sumathi\\pulse\\data\\map\\user\\hover\\country\\india\\state\"\n",
    "map_user_states = os.listdir(path_map_user)\n",
    "\n",
    "# 3. Iterative loops (States -> Years -> Quarters)\n",
    "for i in map_user_states:\n",
    "    p_i = os.path.join(path_map_user, i)\n",
    "    year_map_user=os.listdir(p_i)\n",
    "\n",
    "    for j in year_map_user:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        quarter_map_user=os.listdir(p_j)\n",
    "\n",
    "        for k in quarter_map_user:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            \n",
    "            with open(p_k, 'r') as Data:\n",
    "                D = json.load(Data)\n",
    "            \n",
    "            # 4. Map User uses 'hoverData' (Dictionary format)\n",
    "            if D['data']['hoverData'] is not None:\n",
    "                try:\n",
    "                    # We use .items() because District names are keys in this JSON\n",
    "                    for district_name, values in D['data']['hoverData'].items():\n",
    "                        \n",
    "                        # Extracting specific user metrics\n",
    "                        reg_users = values['registeredUsers']\n",
    "                        app_opens = values['appOpens']\n",
    "                        \n",
    "                        map_user_data['State'].append(i)\n",
    "                        map_user_data['Year'].append(j)\n",
    "                        map_user_data['Quarter'].append(int(k.strip('.json')))\n",
    "                        map_user_data['District'].append(district_name)\n",
    "                        map_user_data['Registered_Users'].append(reg_users)\n",
    "                        map_user_data['App_Opens'].append(app_opens)\n",
    "                \n",
    "                except (KeyError, TypeError):\n",
    "                    continue\n",
    "\n",
    "# 6. Create the final DataFrame\n",
    "Map_User = pd.DataFrame(map_user_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3e0ccd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top insurance:\n",
    "path_top_ins = \"C:/Users/Sumathi/pulse/data/top/insurance/country/india/state/\"\n",
    "top_ins_states = os.listdir(path_top_ins)\n",
    "\n",
    "# Storage dictionaries\n",
    "storage_top_ins_dist = {'State': [], 'Year': [], 'Quarter': [], 'District_Name': [], 'Count': [], 'Amount': []}\n",
    "storage_top_ins_pin = {'State': [], 'Year': [], 'Quarter': [], 'Pincode': [], 'Count': [], 'Amount': []}\n",
    "\n",
    "for i in top_ins_states:\n",
    "    p_i = os.path.join(path_top_ins, i)    \n",
    "    Top_ins_yr = os.listdir(p_i)\n",
    "    \n",
    "    for j in Top_ins_yr:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        Top_ins_yr_list = os.listdir(p_j)\n",
    "        \n",
    "        for k in Top_ins_yr_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            \n",
    "            try:\n",
    "                with open(p_k, 'r') as Data:\n",
    "                    D = json.load(Data)\n",
    "\n",
    "                # --- 1. EXTRACT DISTRICTS ---\n",
    "                for z in D['data']['districts']:\n",
    "                    # Temporary variable assignment\n",
    "                    name = z['entityName']\n",
    "                    count = z['metric']['count']\n",
    "                    amount = z['metric']['amount']\n",
    "                   \n",
    "                    storage_top_ins_dist['District_Name'].append(name)\n",
    "                    storage_top_ins_dist['Count'].append(count)\n",
    "                    storage_top_ins_dist['Amount'].append(amount)\n",
    "                    storage_top_ins_dist['State'].append(i)\n",
    "                    storage_top_ins_dist['Year'].append(j)\n",
    "                    storage_top_ins_dist['Quarter'].append(int(k.strip('.json')))\n",
    "                    \n",
    "\n",
    "                # --- 2. EXTRACT PINCODES ---\n",
    "                for z in D['data']['pincodes']:\n",
    "                    # Temporary variable assignment\n",
    "                    pincode = z['entityName']\n",
    "                    count = z['metric']['count']\n",
    "                    amount = z['metric']['amount']\n",
    "                    \n",
    "                    storage_top_ins_pin['State'].append(i)\n",
    "                    storage_top_ins_pin['Year'].append(j)\n",
    "                    storage_top_ins_pin['Quarter'].append(int(k.strip('.json')))\n",
    "                    storage_top_ins_pin['Pincode'].append(pincode)\n",
    "                    storage_top_ins_pin['Count'].append(count)\n",
    "                    storage_top_ins_pin['Amount'].append(amount)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {p_k}: {e}\")\n",
    "                continue\n",
    "\n",
    "# Convert to DataFrames\n",
    "Top_Ins_Dist = pd.DataFrame(storage_top_ins_dist)\n",
    "Top_Ins_Pin = pd.DataFrame(storage_top_ins_pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c655e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for Top Transaction\n",
    "path_top_trans = \"C:/Users/Sumathi/pulse/data/top/transaction/country/india/state/\"\n",
    "top_trans_states = os.listdir(path_top_trans)\n",
    "\n",
    "# Dictionaries for Districts and Pincodes\n",
    "storage_top_trans_dist = {'State': [], 'Year': [], 'Quarter': [], 'District_Name': [], 'Count': [], 'Amount': []}\n",
    "storage_top_trans_pin = {'State': [], 'Year': [], 'Quarter': [], 'Pincode': [], 'Count': [], 'Amount': []}\n",
    "\n",
    "for i in top_trans_states:\n",
    "    p_i = os.path.join(path_top_trans, i)\n",
    "    Agg_trans_yr = os.listdir(p_i)\n",
    "    \n",
    "    for j in Agg_trans_yr:\n",
    "        p_j = os.path.join(p_i, j)\n",
    "        Agg_trans_yr_list = os.listdir(p_j)\n",
    "        \n",
    "        for k in Agg_trans_yr_list:\n",
    "            p_k = os.path.join(p_j, k)\n",
    "            \n",
    "            try:\n",
    "                with open(p_k, 'r') as Data:\n",
    "                    D = json.load(Data)\n",
    "\n",
    "                # --- 1. DISTRICTS ---\n",
    "                for z in D['data']['districts']:\n",
    "                    name = z['entityName']\n",
    "                    count = z['metric']['count']\n",
    "                    amount = z['metric']['amount']\n",
    "                    \n",
    "                    storage_top_trans_dist['District_Name'].append(name)\n",
    "                    storage_top_trans_dist['Count'].append(count)\n",
    "                    storage_top_trans_dist['Amount'].append(amount)\n",
    "                    storage_top_trans_dist['State'].append(i)\n",
    "                    storage_top_trans_dist['Year'].append(j)\n",
    "                    storage_top_trans_dist['Quarter'].append(int(k.strip('.json')))\n",
    "                    \n",
    "                # --- 2. PINCODES ---\n",
    "                for z in D['data']['pincodes']:\n",
    "                    pincode = z['entityName']\n",
    "                    count = z['metric']['count']\n",
    "                    amount = z['metric']['amount']\n",
    "                    \n",
    "                    storage_top_trans_pin['Pincode'].append(pincode)\n",
    "                    storage_top_trans_pin['Count'].append(count)\n",
    "                    storage_top_trans_pin['Amount'].append(amount)\n",
    "                    storage_top_trans_pin['State'].append(i)\n",
    "                    storage_top_trans_pin['Year'].append(j)\n",
    "                    storage_top_trans_pin['Quarter'].append(int(k.strip('.json')))\n",
    "                    \n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {p_k}: {e}\")\n",
    "                continue\n",
    "                \n",
    "\n",
    "# Convert to DataFrames\n",
    "Top_Trans_Dist = pd.DataFrame(storage_top_trans_dist)\n",
    "Top_Trans_Pin = pd.DataFrame(storage_top_trans_pin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "612c9d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"success\": true,\n",
      "    \"code\": \"SUCCESS\",\n",
      "    \"data\": {\n",
      "        \"states\": null,\n",
      "        \"districts\": [\n",
      "            {\n",
      "                \"name\": \"south andaman\",\n",
      "                \"registeredUsers\": 5846\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"north and middle andaman\",\n",
      "                \"registeredUsers\": 632\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"nicobars\",\n",
      "                \"registeredUsers\": 262\n",
      "            }\n",
      "        ],\n",
      "        \"pincodes\": [\n",
      "            {\n",
      "                \"name\": \"744103\",\n",
      "                \"registeredUsers\": 1608\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"744101\",\n",
      "                \"registeredUsers\": 1108\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"744105\",\n",
      "                \"registeredUsers\": 1075\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"744102\",\n",
      "                \"registeredUsers\": 1006\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"744104\",\n",
      "                \"registeredUsers\": 272\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"744202\",\n",
      "                \"registeredUsers\": 237\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"744112\",\n",
      "                \"registeredUsers\": 215\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"744301\",\n",
      "                \"registeredUsers\": 207\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"744107\",\n",
      "                \"registeredUsers\": 196\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"744211\",\n",
      "                \"registeredUsers\": 156\n",
      "            }\n",
      "        ]\n",
      "    },\n",
      "    \"responseTimestamp\": 1630501494546\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Pick any one file path that you know exists\n",
    "test_path = \"C:/Users/Sumathi/pulse/data/top/user/country/india/state/andaman-&-nicobar-islands/2018/1.json\"\n",
    "\n",
    "with open(test_path, 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Use indent=4 to make it readable\n",
    "print(json.dumps(data, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0f722779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path setup for top User:\n",
    "path_top_user=r\"C:\\Users\\Sumathi\\pulse\\data\\top\\user\\country\\india\\state\"\n",
    "top_user_states=os.listdir(path_top_user)\n",
    "\n",
    "#seperate empty dictionary for district and Pincode\n",
    "Storage_top_user_dist={'State':[],'Year':[],'Quarter':[], 'District_name':[],'Registered_User':[] }\n",
    "Storage_top_user_pincode={'State':[],'Year':[],'Quarter':[], 'Pincode':[],'Registered_User':[] }\n",
    "\n",
    "for i in top_user_states:\n",
    "    p_i=os.path.join(path_top_user,i)\n",
    "    Top_user_year=os.listdir(p_i)\n",
    "\n",
    "    for j in Top_user_year:\n",
    "        p_j=os.path.join(p_i,j)\n",
    "        Top_user_year_list=os.listdir(p_j)\n",
    "\n",
    "        for k in  Top_user_year_list:\n",
    "            p_k=os.path.join(p_j,k)\n",
    "            \n",
    "            try:\n",
    "                with open(p_k,'r') as Data:\n",
    "                    D=json.load(Data)\n",
    "\n",
    "#for Top districts:\n",
    "                for z in D['data']['districts']:\n",
    "                    name=z['name']\n",
    "                    reg_users_d=z['registeredUsers'] \n",
    "\n",
    "                    Storage_top_user_dist['State'].append(i)\n",
    "                    Storage_top_user_dist['Year'].append(j)\n",
    "                    Storage_top_user_dist['Quarter'].append(int(k.strip('.json')))\n",
    "                    Storage_top_user_dist['District_name'].append(name)\n",
    "                    Storage_top_user_dist['Registered_User'].append(reg_users_d)\n",
    "\n",
    "#Top pincodes:\n",
    "                for z in D['data']['pincodes']:\n",
    "                    name=z['name']\n",
    "                    reg_users=z['registeredUsers']\n",
    "\n",
    "                    Storage_top_user_pincode['State'].append(i)\n",
    "                    Storage_top_user_pincode['Year'].append(j)\n",
    "                    Storage_top_user_pincode['Quarter'].append(int(k.strip('.json')))\n",
    "                    Storage_top_user_pincode['Pincode'].append(name)\n",
    "                    Storage_top_user_pincode['Registered_User'].append(reg_users)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing file {p_k}: {e}\")\n",
    "                continue\n",
    "\n",
    "Top_User_District=pd.DataFrame(Storage_top_user_dist)            \n",
    "Top_User_Pincode=pd.DataFrame(Storage_top_user_pincode)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0cde9fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Check complete! All 12 tables are now live in your Render database ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# 1. Establish Connection\n",
    "db_url = 'postgresql+psycopg2://myfile_b4pj_user:RxzB7LFmv8FVCLhAdmEBBZJeEhHWXhWi@dpg-d5vngiffte5s73ctc9cg-a.singapore-postgres.render.com/myfile_b4pj'\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "# 2. Push Aggregated Data\n",
    "#Agg_Trans.to_sql('aggregated_transaction', engine, if_exists='replace', index=False)\n",
    "#Agg_User.to_sql('aggregated_user', engine, if_exists='replace', index=False)\n",
    "#Agg_Ins.to_sql('aggregated_insurance', engine, if_exists='replace', index=False)\n",
    "\n",
    "# 3. Push Map Data\n",
    "#Map_Trans.to_sql('map_transaction', engine, if_exists='replace', index=False)\n",
    "#Map_User.to_sql('map_user', engine, if_exists='replace', index=False)\n",
    "#Map_Ins.to_sql('map_insurance', engine, if_exists='replace', index=False)\n",
    "\n",
    "# 4. Push Top Data (Transactions)\n",
    "#Top_Trans_Dist.to_sql('top_transaction_district', engine, if_exists='replace', index=False)\n",
    "#Top_Trans_Pin.to_sql('top_transaction_pincode', engine, if_exists='replace', index=False)\n",
    "\n",
    "# 5. Push Top Data (Users)\n",
    "#Top_User_District.to_sql('top_user_district', engine, if_exists='replace', index=False)\n",
    "#Top_User_Pincode.to_sql('top_user_pincode', engine, if_exists='replace', index=False)\n",
    "\n",
    "# 6. Push Top Data (Insurance)\n",
    "#Top_Ins_Dist.to_sql('top_insurance_district', engine, if_exists='replace', index=False)\n",
    "#Top_Ins_Pin.to_sql('top_insurance_pincode', engine, if_exists='replace', index=False)\n",
    "\n",
    "print(\"--- Check complete! All 12 tables are now live in your Render database ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e65c074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Successfully loaded 12 DataFrames into memory! ---\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# 1. Connection\n",
    "db_url = 'postgresql+psycopg2://myfile_b4pj_user:RxzB7LFmv8FVCLhAdmEBBZJeEhHWXhWi@dpg-d5vngiffte5s73ctc9cg-a.singapore-postgres.render.com/myfile_b4pj'\n",
    "engine = create_engine(db_url)\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    # --- Aggregated Tables ---\n",
    "    df_agg_trans = pd.read_sql_query(text(\"SELECT * FROM aggregated_transaction\"), conn)\n",
    "    df_agg_user  = pd.read_sql_query(text(\"SELECT * FROM aggregated_user\"), conn)\n",
    "    df_agg_ins   = pd.read_sql_query(text(\"SELECT * FROM aggregated_insurance\"), conn)\n",
    "\n",
    "    # --- Map Tables ---\n",
    "    df_map_trans = pd.read_sql_query(text(\"SELECT * FROM map_transaction\"), conn)\n",
    "    df_map_user  = pd.read_sql_query(text(\"SELECT * FROM map_user\"), conn)\n",
    "    df_map_ins   = pd.read_sql_query(text(\"SELECT * FROM map_insurance\"), conn)\n",
    "\n",
    "    # --- Top Tables (Transactions) ---\n",
    "    df_top_trans_dist = pd.read_sql_query(text(\"SELECT * FROM top_transaction_district\"), conn)\n",
    "    df_top_trans_pin  = pd.read_sql_query(text(\"SELECT * FROM top_transaction_pincode\"), conn)\n",
    "\n",
    "    # --- Top Tables (Users) ---\n",
    "    df_top_user_dist = pd.read_sql_query(text(\"SELECT * FROM top_user_district\"), conn)\n",
    "    df_top_user_pin  = pd.read_sql_query(text(\"SELECT * FROM top_user_pincode\"), conn)\n",
    "\n",
    "    # --- Top Tables (Insurance) ---\n",
    "    df_top_ins_dist = pd.read_sql_query(text(\"SELECT * FROM top_insurance_district\"), conn)\n",
    "    df_top_ins_pin  = pd.read_sql_query(text(\"SELECT * FROM top_insurance_pincode\"), conn)\n",
    "\n",
    "print(\"--- Successfully loaded 12 DataFrames into memory! ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e704b358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4adff022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---  DATA INTEGRITY & STRUCTURE REPORT ---\n",
      "\n",
      "TABLE: Aggregated Trans\n",
      "  - Rows: 5034 | Columns: 6\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 236.1 KB\n",
      "\n",
      "TABLE: Aggregated User\n",
      "  - Rows: 6732 | Columns: 8\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 420.9 KB\n",
      "\n",
      "TABLE: Aggregated Ins\n",
      "  - Rows: 682 | Columns: 6\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 32.1 KB\n",
      "\n",
      "TABLE: Map Trans\n",
      "  - Rows: 5180 | Columns: 6\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 242.9 KB\n",
      "\n",
      "TABLE: Map User\n",
      "  - Rows: 20608 | Columns: 6\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 966.1 KB\n",
      "\n",
      "TABLE: Map Ins\n",
      "  - Rows: 13876 | Columns: 6\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 650.6 KB\n",
      "\n",
      "TABLE: Top Trans Dist\n",
      "  - Rows: 8296 | Columns: 6\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 389.0 KB\n",
      "\n",
      "TABLE: Top Trans Pin\n",
      "  - Rows: 9999 | Columns: 6\n",
      "  - Missing Values (Nulls): 2\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 468.8 KB\n",
      "\n",
      "TABLE: Top User Dist\n",
      "  - Rows: 8296 | Columns: 5\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 324.2 KB\n",
      "\n",
      "TABLE: Top User Pin\n",
      "  - Rows: 10000 | Columns: 5\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 390.8 KB\n",
      "\n",
      "TABLE: Top Ins Dist\n",
      "  - Rows: 5608 | Columns: 6\n",
      "  - Missing Values (Nulls): 0\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 263.0 KB\n",
      "\n",
      "TABLE: Top Ins Pin\n",
      "  - Rows: 6668 | Columns: 6\n",
      "  - Missing Values (Nulls): 3\n",
      "  - Duplicates: 0\n",
      "  - Memory Usage: 312.7 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_dfs = {\n",
    "    \"Aggregated Trans\": df_agg_trans, \"Aggregated User\": df_agg_user, \"Aggregated Ins\": df_agg_ins,\n",
    "    \"Map Trans\": df_map_trans, \"Map User\": df_map_user, \"Map Ins\": df_map_ins,\n",
    "    \"Top Trans Dist\": df_top_trans_dist, \"Top Trans Pin\": df_top_trans_pin,\n",
    "    \"Top User Dist\": df_top_user_dist, \"Top User Pin\": df_top_user_pin,\n",
    "    \"Top Ins Dist\": df_top_ins_dist, \"Top Ins Pin\": df_top_ins_pin\n",
    "}\n",
    "\n",
    "print(\"---  DATA INTEGRITY & STRUCTURE REPORT ---\")\n",
    "for name, df in all_dfs.items():\n",
    "    print(f\"\\nTABLE: {name}\")\n",
    "    print(f\"  - Rows: {df.shape[0]} | Columns: {df.shape[1]}\")\n",
    "    print(f\"  - Missing Values (Nulls): {df.isnull().sum().sum()}\")\n",
    "    print(f\"  - Duplicates: {df.duplicated().sum()}\")\n",
    "    print(f\"  - Memory Usage: {df.memory_usage().sum() / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "60a063c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>Count</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4810</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.009866e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4852</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13717</td>\n",
       "      <td>3.671160e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State  Year  Quarter Pincode  Count        Amount\n",
       "4810  ladakh  2019        4     NaN   2014  1.009866e+07\n",
       "4852  ladakh  2020        4     NaN  13717  3.671160e+07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_rows = df_top_trans_pin.loc[df_top_trans_pin.isnull().any(axis=1)]\n",
    "display(null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1e59ac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Pincode</th>\n",
       "      <th>Count</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3207</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>658.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3284</th>\n",
       "      <td>ladakh</td>\n",
       "      <td>2022</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>16020.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       State  Year  Quarter Pincode  Count   Amount\n",
       "3199  ladakh  2020        3     NaN      1    281.0\n",
       "3207  ladakh  2020        4     NaN      1    658.0\n",
       "3284  ladakh  2022        4     NaN      8  16020.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "null_rows = df_top_ins_pin.loc[df_top_ins_pin.isnull().any(axis=1)]\n",
    "display(null_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "383c5d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_trans_pin['Pincode'] = df_top_trans_pin['Pincode'].fillna('Unknown')\n",
    "df_top_ins_pin['Pincode'] = df_top_ins_pin['Pincode'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c0f76074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "State      0\n",
       "Year       0\n",
       "Quarter    0\n",
       "Pincode    0\n",
       "Count      0\n",
       "Amount     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_trans_pin.isnull().sum()\n",
    "df_top_ins_pin.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a89739",
   "metadata": {},
   "source": [
    "                                        Business Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61fdbfb",
   "metadata": {},
   "source": [
    "                     1. Decoding Transaction Dynamics on PhonePe Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e7e7c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables found in database: ['aggregated_transaction', 'aggregated_user', 'aggregated_insurance', 'map_transaction', 'map_user', 'map_insurance', 'top_transaction_district', 'top_transaction_pincode', 'top_user_district', 'top_user_pincode', 'top_insurance_district', 'top_insurance_pincode', 'agg_trans']\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "\n",
    "inspector = inspect(engine)\n",
    "print(\"Tables found in database:\", inspector.get_table_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ed83a963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# 1. Connection (using your URL)\n",
    "db_url = 'postgresql+psycopg2://myfile_b4pj_user:RxzB7LFmv8FVCLhAdmEBBZJeEhHWXhWi@dpg-d5vngiffte5s73ctc9cg-a.singapore-postgres.render.com/myfile_b4pj'\n",
    "engine = create_engine(db_url)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c7897",
   "metadata": {},
   "source": [
    "                   1. Decoding Transaction Dynamics on PhonePe Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0e26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             State  total_amount\n",
      "0        karnataka  1.532931e+13\n",
      "1      maharashtra  1.478439e+13\n",
      "2        telangana  1.407568e+13\n",
      "3   andhra-pradesh  1.287331e+13\n",
      "4    uttar-pradesh  1.111335e+13\n",
      "5        rajasthan  1.011290e+13\n",
      "6            bihar  7.403791e+12\n",
      "7   madhya-pradesh  7.169488e+12\n",
      "8      west-bengal  6.387113e+12\n",
      "9           odisha  4.803920e+12\n",
      "10      tamil-nadu  4.037425e+12\n"
     ]
    }
   ],
   "source": [
    " #1. TOp 10 states that led the way in total_transaction value in 2024\n",
    "\n",
    "query = text(\"\"\"\n",
    "    SELECT \"State\", SUM(\"Transaction_amount\") AS Total_Amount \n",
    "    FROM aggregated_transaction\n",
    "    WHERE \"Year\" = '2024'\n",
    "    GROUP BY \"State\"\n",
    "    ORDER BY Total_Amount DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "# 2. Use  'engine' to run it\n",
    "with engine.connect() as conn:\n",
    "    df_top_10 = pd.read_sql(query, conn)\n",
    "\n",
    "# 3. View the result\n",
    "print(df_top_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e92c0a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 State  total_amount\n",
      "0                          lakshadweep  7.164300e+08\n",
      "1                              mizoram  1.581363e+10\n",
      "2            andaman-&-nicobar-islands  3.073972e+10\n",
      "3                               ladakh  3.971840e+10\n",
      "4                              manipur  4.387420e+10\n",
      "5                               sikkim  4.396317e+10\n",
      "6                             nagaland  4.729824e+10\n",
      "7                            meghalaya  6.839180e+10\n",
      "8                           chandigarh  7.315972e+10\n",
      "9                           puducherry  7.512889e+10\n",
      "10                             tripura  7.824837e+10\n",
      "11  dadra-&-nagar-haveli-&-daman-&-diu  8.535804e+10\n",
      "12                   arunachal-pradesh  1.224352e+11\n",
      "13                                 goa  1.952828e+11\n",
      "14                    himachal-pradesh  2.280869e+11\n",
      "15                     jammu-&-kashmir  5.284440e+11\n",
      "16                         uttarakhand  6.992134e+11\n",
      "17                              kerala  1.001024e+12\n",
      "18                              punjab  1.012980e+12\n",
      "19                               assam  1.382837e+12\n",
      "20                        chhattisgarh  2.033512e+12\n"
     ]
    }
   ],
   "source": [
    "#Q2.  20 states/UTs had the lowest total transaction volume in 2024\n",
    "query=text(\"\"\" \n",
    "    select \"State\", sum(\"Transaction_amount\") as Total_amount from aggregated_transaction  \n",
    "    where \"Year\" = '2024'\n",
    "    group by \"State\"\n",
    "    order by Total_amount asc\n",
    "    limit 21 \n",
    " \"\"\")\n",
    "# 2. Use  'engine' to run it\n",
    "with engine.connect() as conn:\n",
    "    df_least_20 = pd.read_sql(query, conn)\n",
    "\n",
    "# 3. View the result\n",
    "print(df_least_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "165a7f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [State, amt_2023, amt_2024]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#Q3 states experienced a revenue decline or market contraction in 2024\n",
    "query=text(\"\"\" \n",
    " SELECT \"State\", SUM(CASE WHEN \"Year\" = '2023' THEN \"Transaction_amount\" ELSE 0 END) AS Amt_2023,SUM(CASE WHEN \"Year\" = '2024' THEN \"Transaction_amount\" ELSE 0 END) AS Amt_2024\n",
    " FROM aggregated_transaction\n",
    " WHERE \"Year\" IN ('2023', '2024')\n",
    " GROUP BY \"State\"\n",
    " HAVING SUM(CASE WHEN \"Year\" = '2024' THEN \"Transaction_amount\" ELSE 0 END) < SUM(CASE WHEN \"Year\" = '2023' THEN \"Transaction_amount\" ELSE 0 END);\n",
    "\"\"\")\n",
    "# 2. Use  'engine' to run it\n",
    "with engine.connect() as conn:\n",
    "    df_decline = pd.read_sql(query, conn)\n",
    "\n",
    "# 3. View the result\n",
    "print(df_decline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "30064a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 State      amt_2023      amt_2024\n",
      "0                             nagaland  3.412667e+10  4.729824e+10\n",
      "1                               punjab  8.060553e+11  1.012980e+12\n",
      "2                         chhattisgarh  1.388610e+12  2.033512e+12\n",
      "3                              gujarat  2.746058e+12  3.821810e+12\n",
      "4                      jammu-&-kashmir  3.115380e+11  5.284440e+11\n",
      "5                                  goa  1.551720e+11  1.952828e+11\n",
      "6                    arunachal-pradesh  8.145647e+10  1.224352e+11\n",
      "7                               kerala  8.467517e+11  1.001024e+12\n",
      "8                                delhi  2.780981e+12  3.744696e+12\n",
      "9                           tamil-nadu  3.197922e+12  4.037425e+12\n",
      "10                          puducherry  6.307812e+10  7.512889e+10\n",
      "11                             haryana  2.712655e+12  3.667399e+12\n",
      "12                         lakshadweep  3.976678e+08  7.164300e+08\n",
      "13  dadra-&-nagar-haveli-&-daman-&-diu  5.901876e+10  8.535804e+10\n",
      "14                         maharashtra  1.081848e+13  1.478439e+13\n",
      "15                               assam  9.771266e+11  1.382837e+12\n",
      "16                       uttar-pradesh  7.592748e+12  1.111335e+13\n",
      "17                             manipur  2.345805e+10  4.387420e+10\n",
      "18                              odisha  3.372391e+12  4.803920e+12\n",
      "19                         uttarakhand  5.180986e+11  6.992134e+11\n",
      "20                             tripura  5.927653e+10  7.824837e+10\n",
      "21                           karnataka  1.147508e+13  1.532931e+13\n",
      "22           andaman-&-nicobar-islands  2.093302e+10  3.073972e+10\n",
      "23                          chandigarh  5.894731e+10  7.315972e+10\n",
      "24                           jharkhand  1.706691e+12  2.493756e+12\n",
      "25                    himachal-pradesh  1.747508e+11  2.280869e+11\n",
      "26                      andhra-pradesh  1.021102e+13  1.287331e+13\n",
      "27                           rajasthan  7.119974e+12  1.011290e+13\n",
      "28                      madhya-pradesh  4.928792e+12  7.169488e+12\n",
      "29                         west-bengal  4.227142e+12  6.387113e+12\n",
      "30                           telangana  1.105735e+13  1.407568e+13\n",
      "31                             mizoram  1.279440e+10  1.581363e+10\n",
      "32                              ladakh  2.623368e+10  3.971840e+10\n",
      "33                               bihar  4.848213e+12  7.403791e+12\n",
      "34                           meghalaya  4.644904e+10  6.839180e+10\n",
      "35                              sikkim  3.204076e+10  4.396317e+10\n"
     ]
    }
   ],
   "source": [
    "# Q4 states achieved positive growth in 2024 compared to 2023 \n",
    "query=text(\"\"\" \n",
    " SELECT \"State\", SUM(CASE WHEN \"Year\" = '2023' THEN \"Transaction_amount\" ELSE 0 END) AS Amt_2023,SUM(CASE WHEN \"Year\" = '2024' THEN \"Transaction_amount\" ELSE 0 END) AS Amt_2024\n",
    " FROM aggregated_transaction\n",
    " WHERE \"Year\" IN ('2023', '2024')\n",
    " GROUP BY \"State\"\n",
    " HAVING SUM(CASE WHEN \"Year\" = '2024' THEN \"Transaction_amount\" ELSE 0 END) > SUM(CASE WHEN \"Year\" = '2023' THEN \"Transaction_amount\" ELSE 0 END);\n",
    "\"\"\")\n",
    "# 2. Use  'engine' to run it\n",
    "with engine.connect() as conn:\n",
    "    df_comparision = pd.read_sql(query, conn)\n",
    "\n",
    "# 3. View the result\n",
    "print(df_comparision)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "73a14c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Transaction_type   total_value\n",
      "0     Peer-to-peer payments  2.822292e+12\n",
      "1         Merchant payments  6.857710e+11\n",
      "2  Recharge & bill payments  1.118492e+11\n",
      "3        Financial Services  1.767093e+09\n",
      "4                    Others  1.656199e+09\n"
     ]
    }
   ],
   "source": [
    "# Q5 breakdown of transaction types in Assam and Meghalaya\t\n",
    "query=(\"\"\" \n",
    " SELECT \"Transaction_type\", sum(\"Transaction_amount\") as Total_value\n",
    " FROM aggregated_transaction\n",
    " WHERE \"State\" in ('assam','meghalaya')\n",
    " GROUP BY \"Transaction_type\"\n",
    " ORDER BY Total_value Desc; \n",
    "\"\"\")\n",
    "# 2. Use  'engine' to run it\n",
    "with engine.connect() as conn:\n",
    "    df_transaction_types = pd.read_sql(query, conn)\n",
    "\n",
    "# 3. View the result\n",
    "print(df_transaction_types)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "82fe80e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  yearly_count\n",
      "0  2018  1.080202e+09\n",
      "1  2019  4.079827e+09\n",
      "2  2020  7.973975e+09\n",
      "3  2021  1.928843e+10\n",
      "4  2022  3.930129e+10\n",
      "5  2023  6.425705e+10\n",
      "6  2024  9.930343e+10\n"
     ]
    }
   ],
   "source": [
    "# PhonePe's transaction volume grown across India each year\n",
    "query=(\"\"\" \n",
    " SELECT \"Year\", SUM(\"Transaction_count\") AS Yearly_Count\n",
    " FROM aggregated_transaction\n",
    " GROUP BY \"Year\"\n",
    " ORDER BY \"Year\" ASC;\n",
    "\"\"\")\n",
    "# 2. Use  'engine' to run it\n",
    "with engine.connect() as conn:\n",
    "    df_transaction_count = pd.read_sql(query, conn)\n",
    "\n",
    "# 3. View the result\n",
    "print(df_transaction_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf3cf48",
   "metadata": {},
   "source": [
    "2.      Device Dominance and User Engagement Analysis Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f16b7ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Brand   total_users\n",
      "0   Samsung  3.460325e+09\n",
      "1    Realme  3.460325e+09\n",
      "2      Vivo  3.460325e+09\n",
      "3    Others  3.460325e+09\n",
      "4    Xiaomi  3.460325e+09\n",
      "5      Oppo  3.460325e+09\n",
      "6  Motorola  3.339301e+09\n",
      "7    Huawei  3.235551e+09\n",
      "8     Apple  3.091083e+09\n",
      "9   OnePlus  2.693291e+09\n"
     ]
    }
   ],
   "source": [
    "#1.Which mobile brands are the most popular among PhonePe users across India?\n",
    "\n",
    "query=(\"\"\"\n",
    " SELECT \"Brand\", sum(\"Registered_Users\") as Total_Users\n",
    " FROM aggregated_user\n",
    " GROUP BY \"Brand\"\n",
    " ORDER BY Total_Users DESC\n",
    " LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "# 2. Use  'engine' to run it\n",
    "with engine.connect() as conn:\n",
    "    df_Brand = pd.read_sql(query, conn)\n",
    "\n",
    "# 3. View the result\n",
    "print(df_Brand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060e0454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            sum\n",
      "0  4.578531e+09\n"
     ]
    }
   ],
   "source": [
    "#Q2 How many total registration records exist where zero app activity (App Opens = 0) was recorded?\"\n",
    "\n",
    "query=(\"\"\"SELECT sum(\"Registered_Users\")\n",
    "FROM aggregated_user\n",
    "WHERE \"App_Opens\"=0;\n",
    "\"\"\")\n",
    "\n",
    "# 2. Use  'engine' to run it\n",
    "with engine.connect() as conn:\n",
    "    df_zero_activity = pd.read_sql(query, conn)\n",
    "\n",
    "# 3. View the result\n",
    "print(df_zero_activity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d5cd4991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 State  inactive_users\n",
      "0                          maharashtra     598734961.0\n",
      "1                        uttar-pradesh     462373032.0\n",
      "2                            karnataka     370733583.0\n",
      "3                       andhra-pradesh     311377385.0\n",
      "4                            telangana     299280080.0\n",
      "5                            rajasthan     292793171.0\n",
      "6                          west-bengal     275209297.0\n",
      "7                              gujarat     252126952.0\n",
      "8                       madhya-pradesh     242928609.0\n",
      "9                           tamil-nadu     225468628.0\n",
      "10                               bihar     213905923.0\n",
      "11                               delhi     203254150.0\n",
      "12                             haryana     172115042.0\n",
      "13                              odisha     159721859.0\n",
      "14                           jharkhand      86262011.0\n",
      "15                              punjab      83212635.0\n",
      "16                              kerala      78015509.0\n",
      "17                        chhattisgarh      69702886.0\n",
      "18                         uttarakhand      45978405.0\n",
      "19                               assam      44433301.0\n",
      "20                    himachal-pradesh      23428394.0\n",
      "21                     jammu-&-kashmir      19225745.0\n",
      "22                                 goa       8815554.0\n",
      "23                          chandigarh       8055322.0\n",
      "24                             tripura       6511109.0\n",
      "25  dadra-&-nagar-haveli-&-daman-&-diu       5212526.0\n",
      "26                          puducherry       4828967.0\n",
      "27                             manipur       3520341.0\n",
      "28                   arunachal-pradesh       2630199.0\n",
      "29                           meghalaya       2128863.0\n",
      "30                              sikkim       2126069.0\n",
      "31                            nagaland       1831588.0\n",
      "32                              ladakh       1022813.0\n",
      "33                             mizoram        831072.0\n",
      "34           andaman-&-nicobar-islands        683232.0\n",
      "35                         lakshadweep         51447.0\n"
     ]
    }
   ],
   "source": [
    "#3. inactive users state wise\n",
    "query = (\"\"\"\n",
    "    SELECT \"State\", SUM(\"Registered_Users\") AS Inactive_Users\n",
    "    FROM aggregated_User\n",
    "    WHERE \"App_Opens\" = 0\n",
    "    GROUP BY \"State\"\n",
    "    ORDER BY Inactive_Users DESC;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_inactive_states = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_inactive_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3643ccf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               State   total_opens   total_users  engagement_ratio\n",
      "0          rajasthan  1.000934e+11  2.372101e+09             42.20\n",
      "1     andhra-pradesh  1.024454e+11  2.479563e+09             41.32\n",
      "2          telangana  9.263988e+10  2.330985e+09             39.74\n",
      "3  arunachal-pradesh  1.172571e+09  3.086127e+07             37.99\n",
      "4          karnataka  1.215057e+11  3.205101e+09             37.91\n",
      "5     madhya-pradesh  7.152417e+10  1.987287e+09             35.99\n",
      "6            mizoram  3.530931e+08  1.022955e+07             34.52\n",
      "7             ladakh  3.179896e+08  9.246424e+06             34.39\n",
      "8       chhattisgarh  1.928916e+10  5.955061e+08             32.39\n",
      "9             odisha  3.853636e+10  1.260387e+09             30.58\n"
     ]
    }
   ],
   "source": [
    "#4. Active users\n",
    "query = text(\"\"\"\n",
    "    SELECT \"State\",SUM(\"App_Opens\") AS Total_opens, SUM(\"Registered_Users\") AS Total_users,\n",
    "    ROUND((SUM(\"App_Opens\")::numeric / NULLIF(SUM(\"Registered_Users\"), 0)), 2) AS Engagement_Ratio\n",
    "    FROM aggregated_user\n",
    "    GROUP BY \"State\"\n",
    "    ORDER BY Engagement_Ratio DESC\n",
    "    LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_engagement = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_engagement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "585be50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Quarter  total_oppens\n",
      "0        1  3.204137e+11\n",
      "1        4  2.962861e+11\n",
      "2        3  2.358837e+11\n",
      "3        2  1.639947e+11\n"
     ]
    }
   ],
   "source": [
    "#5 In which quarter do users engage with the app the most?\n",
    "query = text(\"\"\"\n",
    "    SELECT \"Quarter\", sum(\"App_Opens\") Total_oppens\n",
    "    FROM aggregated_user\n",
    "    GROUP BY \"Quarter\"\n",
    "    ORDER BY Total_oppens desc;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_quarter = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a447e03",
   "metadata": {},
   "source": [
    "3.          Insurance Engagement Analysis Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfebed3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         State                     District  total_policies\n",
      "0    karnataka     bengaluru urban district       1117691.0\n",
      "1  maharashtra                pune district        396173.0\n",
      "2  maharashtra               thane district        260578.0\n",
      "3   tamil-nadu             chennai district        251081.0\n",
      "4  maharashtra     mumbai suburban district        211311.0\n",
      "5    telangana          rangareddy district        206714.0\n",
      "6    telangana  medchal malkajgiri district        178028.0\n",
      "7    rajasthan              jaipur district        177296.0\n",
      "8    telangana           hyderabad district        169470.0\n",
      "9      haryana            gurugram district        168368.0\n"
     ]
    }
   ],
   "source": [
    "#1 Which specific districts across India are leading in insurance adoption?\n",
    "import pandas as pd\n",
    "from sqlalchemy import text\n",
    "query = text(\"\"\"\n",
    "    SELECT \"State\", \"District\", \n",
    "           SUM(\"Insurance_Count\") AS Total_policies\n",
    "    FROM map_insurance\n",
    "    GROUP BY \"State\", \"District\"\n",
    "    ORDER BY Total_policies DESC\n",
    "    LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_top_districts = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_top_districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0a631ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Quarter   total_value\n",
      "0        4  6.415368e+09\n",
      "1        3  4.873032e+09\n",
      "2        1  4.434409e+09\n",
      "3        2  4.292770e+09\n"
     ]
    }
   ],
   "source": [
    "# 2 Is there a specific time of year when people are more likely to buy insurance? Do we see a spike in a particular quarter?\n",
    "query = text(\"\"\"\n",
    "    SELECT \"Quarter\", sum(\"Insurance_Amount\")as Total_value\n",
    "    FROM map_insurance\n",
    "    GROUP BY \"Quarter\"\n",
    "    ORDER BY Total_value desc;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_relation = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb3f288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         State                     District  total_policies  total_value\n",
      "0    karnataka     bengaluru urban district        357490.0  584075839.0\n",
      "1  maharashtra                pune district        119733.0  205427182.0\n",
      "2   tamil-nadu             chennai district        108880.0  130200666.0\n",
      "3    telangana          rangareddy district         65526.0  117375694.0\n",
      "4    rajasthan              jaipur district         64388.0  106998743.0\n",
      "5  maharashtra               thane district         74554.0  103927859.0\n",
      "6    telangana  medchal malkajgiri district         54919.0   93228535.0\n",
      "7       kerala           ernakulam district         54064.0   87934298.0\n",
      "8      haryana            gurugram district         59398.0   87357806.0\n",
      "9  maharashtra     mumbai suburban district         65227.0   86023257.0\n"
     ]
    }
   ],
   "source": [
    "# 3.Which specific districts are the 'Growth Engines' for insurance, contributing the highest share to their state's total insurance revenue?\n",
    "query = text(\"\"\"\n",
    "    SELECT \"State\", \"District\", \n",
    "           SUM(\"Insurance_Count\") AS total_policies, \n",
    "           SUM(\"Insurance_Amount\") AS total_value\n",
    "    FROM map_insurance\n",
    "    WHERE \"Year\" = '2024'\n",
    "    GROUP BY \"State\", \"District\"\n",
    "    ORDER BY total_value DESC\n",
    "    LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_district_rank = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_district_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded3434a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  total_policies\n",
      "0  2020        788258.0\n",
      "1  2021       1583282.0\n",
      "2  2022       3090116.0\n",
      "3  2023       3986187.0\n",
      "4  2024       5067844.0\n"
     ]
    }
   ],
   "source": [
    "# 4 Is the demand for insurance increasing over time? \n",
    "    \n",
    "query = text(\"\"\"\n",
    "    SELECT \"Year\", SUM(\"Insurance_Count\") AS total_policies\n",
    "    FROM map_insurance\n",
    "    GROUP BY \"Year\"\n",
    "    ORDER BY \"Year\" ASC;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_yearly_demand = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_yearly_demand)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69dad13",
   "metadata": {},
   "source": [
    "4. User Engagement and Growth Strategy Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "29193194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         State                             District  total_users\n",
      "0    karnataka             bengaluru urban district  303663088.0\n",
      "1  maharashtra                        pune district  199346186.0\n",
      "2  maharashtra                       thane district  122501643.0\n",
      "3    rajasthan                      jaipur district  119739290.0\n",
      "4  maharashtra             mumbai suburban district  119012886.0\n",
      "5    telangana                   hyderabad district  101824322.0\n",
      "6    telangana                  rangareddy district   90261099.0\n",
      "7      gujarat                   ahmadabad district   81767310.0\n",
      "8      gujarat                       surat district   77469508.0\n",
      "9  west-bengal  north twenty four parganas district   77396295.0\n"
     ]
    }
   ],
   "source": [
    "#1.Which 10 districts in India have the largest base of registered PhonePe users?\n",
    "query=(\"\"\" \n",
    " SELECT \"State\", \"District\", SUM(\"Registered_Users\") AS total_users\n",
    " FROM map_user\n",
    " GROUP BY \"State\", \"District\"  \n",
    " ORDER BY total_users DESC\n",
    " LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect () as conn:\n",
    "    df_top_user_districts=pd.read_sql(query,conn)\n",
    "print(df_top_user_districts)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "040cfd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      State            District  total_registration  total_apps_opened  \\\n",
      "0  nagaland    niuland district                85.0              178.0   \n",
      "1   mizoram   khawzawl district              5604.0           548527.0   \n",
      "2   mizoram  hnahthial district              5729.0           567449.0   \n",
      "3  nagaland   tseminyu district              3556.0           784745.0   \n",
      "4   mizoram    saitual district              9503.0           792073.0   \n",
      "5    sikkim     soreng district             34044.0          1805156.0   \n",
      "6  nagaland   shamator district              4068.0          1929911.0   \n",
      "7    sikkim  gyalshing district             48188.0          2670246.0   \n",
      "8    sikkim     mangan district             48528.0          3441899.0   \n",
      "9     assam     bajali district             91432.0          3661953.0   \n",
      "\n",
      "   dormant_users  \n",
      "0          -93.0  \n",
      "1      -542923.0  \n",
      "2      -561720.0  \n",
      "3      -781189.0  \n",
      "4      -782570.0  \n",
      "5     -1771112.0  \n",
      "6     -1925843.0  \n",
      "7     -2622058.0  \n",
      "8     -3393371.0  \n",
      "9     -3570521.0  \n"
     ]
    }
   ],
   "source": [
    "# 2.Which districts show a high number of registrations but a low number of app opens?\n",
    "\n",
    "query=(\"\"\" \n",
    " SELECT \"State\", \"District\", SUM(\"Registered_Users\") AS total_registration,sum(\"App_Opens\") as total_apps_opened,\n",
    " SUM(\"Registered_Users\")-sum(\"App_Opens\") as dormant_users\n",
    " FROM map_user\n",
    " GROUP BY \"State\", \"District\"  \n",
    " ORDER BY dormant_users desc\n",
    " LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect () as conn:\n",
    "    df_dormant_user_districts=pd.read_sql(query,conn)\n",
    "print(df_dormant_user_districts)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "90751ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         State                  District  total_registration  \\\n",
      "0    karnataka  bengaluru urban district         303663088.0   \n",
      "1  maharashtra             pune district         199346186.0   \n",
      "2    rajasthan       ganganagar district          11571144.0   \n",
      "3    rajasthan           barmer district          14138947.0   \n",
      "4  maharashtra           nashik district          62791515.0   \n",
      "5    rajasthan           jaipur district         119739290.0   \n",
      "6    rajasthan      hanumangarh district           9814608.0   \n",
      "7    rajasthan          bikaner district          17292087.0   \n",
      "8    telangana       rangareddy district          90261099.0   \n",
      "9    rajasthan          jodhpur district          30332539.0   \n",
      "\n",
      "   total_apps_opened  active_users  \n",
      "0       8.626629e+09  8.930292e+09  \n",
      "1       6.244893e+09  6.444239e+09  \n",
      "2       4.524202e+09  4.535773e+09  \n",
      "3       3.492608e+09  3.506747e+09  \n",
      "4       3.388420e+09  3.451212e+09  \n",
      "5       3.207851e+09  3.327591e+09  \n",
      "6       3.202109e+09  3.211924e+09  \n",
      "7       3.132601e+09  3.149893e+09  \n",
      "8       3.037773e+09  3.128034e+09  \n",
      "9       2.981714e+09  3.012046e+09  \n"
     ]
    }
   ],
   "source": [
    "# 3 In which districts are users most active, as measured by the total number of times the app is opened?\n",
    "\n",
    "query=(\"\"\" \n",
    " SELECT \"State\", \"District\", SUM(\"Registered_Users\") AS total_registration,sum(\"App_Opens\") as total_apps_opened,\n",
    " SUM(\"Registered_Users\")+sum(\"App_Opens\") as active_users\n",
    " FROM map_user\n",
    " GROUP BY \"State\", \"District\"  \n",
    " ORDER BY active_users desc\n",
    " LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect () as conn:\n",
    "    df_active_user_districts=pd.read_sql(query,conn)\n",
    "print(df_active_user_districts)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4aaaf6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        State                   District    user_base\n",
      "0   karnataka   bengaluru urban district  303663088.0\n",
      "1   karnataka          belagavi district   34297782.0\n",
      "2   karnataka            mysuru district   33079121.0\n",
      "3   karnataka          tumakuru district   22333538.0\n",
      "4   karnataka  dakshina kannada district   22066932.0\n",
      "5   karnataka           dharwad district   21619100.0\n",
      "6   karnataka           ballari district   20692586.0\n",
      "7   karnataka   bengaluru rural district   19715861.0\n",
      "8   karnataka        kalaburagi district   18478130.0\n",
      "9   karnataka        vijayapura district   16705060.0\n",
      "10  karnataka             kolar district   16182907.0\n",
      "11  karnataka        davanagere district   15280127.0\n",
      "12  karnataka        shivamogga district   14888899.0\n",
      "13  karnataka            hassan district   14847259.0\n",
      "14  karnataka            mandya district   13869909.0\n",
      "15  karnataka         bagalkote district   13731582.0\n",
      "16  karnataka           raichur district   13143731.0\n",
      "17  karnataka             bidar district   12604808.0\n",
      "18  karnataka        ramanagara district   11830181.0\n",
      "19  karnataka             udupi district   11341274.0\n",
      "20  karnataka       chitradurga district   11055994.0\n",
      "21  karnataka    uttara kannada district   10405123.0\n",
      "22  karnataka   chikkaballapura district    9907278.0\n",
      "23  karnataka            haveri district    9054312.0\n",
      "24  karnataka            koppal district    8912238.0\n",
      "25  karnataka    chikkamagaluru district    8769933.0\n",
      "26  karnataka             gadag district    6878137.0\n",
      "27  karnataka            yadgir district    5076365.0\n",
      "28  karnataka   chamarajanagara district    4603978.0\n",
      "29  karnataka            kodagu district    4552446.0\n",
      "30  karnataka    chikkaballapur district    1379216.0\n",
      "31  karnataka      vijayanagara district    1181244.0\n",
      "32  karnataka           yadgiri district     808893.0\n",
      "33  karnataka    chamarajanagar district     717204.0\n"
     ]
    }
   ],
   "source": [
    "#4. Within a specific state (e.g., Karnataka), how is the user base distributed across its different districts? Is the growth concentrated in one city or spread out?\n",
    "\n",
    "query=(\"\"\" \n",
    " SELECT \"State\", \"District\", sum(\"Registered_Users\") as user_base\n",
    " FROM map_user\n",
    " WHERE \"State\"='karnataka'\n",
    " group by \"State\",\"District\"\n",
    " order by user_base desc;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect () as conn:\n",
    "    df_user_karnataka=pd.read_sql(query,conn)\n",
    "print(df_user_karnataka)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283ff776",
   "metadata": {},
   "source": [
    "5.              User Registration Analysis Scenario\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "51317b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            State Pincode  total_new_registrations\n",
      "0   uttar-pradesh  201301                 964283.0\n",
      "1     maharashtra  421302                 871910.0\n",
      "2           delhi  110059                 826819.0\n",
      "3       telangana  500072                 755978.0\n",
      "4  madhya-pradesh  452001                 709324.0\n",
      "5     maharashtra  410501                 683451.0\n",
      "6       karnataka  560068                 663903.0\n",
      "7         haryana  121004                 663180.0\n",
      "8   uttar-pradesh  201009                 660474.0\n",
      "9           delhi  110092                 654020.0\n"
     ]
    }
   ],
   "source": [
    "#1.Which 10 Pincodes across India recorded the highest number of new user registrations in the last quarter of 2024?\n",
    "query = text(\"\"\"\n",
    "    SELECT \"State\",  \"Pincode\", sum(\"Registered_User\") as total_new_registrations\n",
    "    FROM top_user_pincode\n",
    "    WHERE \"Year\" = '2024' AND \"Quarter\" = 4\n",
    "    GROUP BY \"State\", \"Pincode\"\n",
    "    ORDER BY total_new_registrations DESC\n",
    "    LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_top_pincodes = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_top_pincodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6fd209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year  Quarter  total_registrations\n",
      "0  2024        2          363063642.0\n"
     ]
    }
   ],
   "source": [
    "#2 Which specific year-quarter combination saw the highest peak in registrations across the top-performing districts?\n",
    "query = text(\"\"\"\n",
    "    SELECT   \"Year\",\"Quarter\" ,sum(\"Registered_User\") AS Total_Registrations\n",
    "    FROM top_user_district\n",
    "    GROUP BY \"Quarter\", \"Year\"\n",
    "    ORDER BY  Total_Registrations desc\n",
    "    LIMIT 1 ;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_top_peak = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_top_peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e030e381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             State        District_name   q1_users   q4_users\n",
      "0          manipur           tamenglong    15465.0        0.0\n",
      "1      maharashtra           aurangabad  2679421.0        0.0\n",
      "2    uttar-pradesh  gautam buddha nagar  3965080.0        0.0\n",
      "3       tamil-nadu         kancheepuram  1636613.0        0.0\n",
      "4          manipur              chandel    12511.0        0.0\n",
      "..             ...                  ...        ...        ...\n",
      "96           delhi                 west  2837958.0  2781222.0\n",
      "97       rajasthan               jaipur  7253881.0  5371681.0\n",
      "98       telangana            hyderabad  5928930.0  5916910.0\n",
      "99     maharashtra      mumbai suburban  7055629.0  6875379.0\n",
      "100    maharashtra                thane  7314981.0  7300941.0\n",
      "\n",
      "[101 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "#3.Which districts showed a decrease in user registrations in Q4 2024 compared to Q1 2024?\n",
    "query = text(\"\"\"\n",
    "    SELECT \"State\", \"District_name\", \n",
    "    SUM(CASE WHEN \"Quarter\" = 1 THEN \"Registered_User\" ELSE 0 END) AS Q1_Users,\n",
    "    SUM(CASE WHEN \"Quarter\" = 4 THEN \"Registered_User\" ELSE 0 END) AS Q4_Users\n",
    "    FROM top_user_district\n",
    "    WHERE \"Year\" = '2024'\n",
    "    GROUP BY \"State\", \"District_name\"\n",
    "    HAVING SUM(CASE WHEN \"Quarter\" = 4 THEN \"Registered_User\" ELSE 0 END) < \n",
    "    SUM(CASE WHEN \"Quarter\" = 1 THEN \"Registered_User\" ELSE 0 END)\n",
    "    ORDER BY Q4_Users ASC;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_top_decrease = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_top_decrease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7cbe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         State Pincode  user_base\n",
      "0   tamil-nadu  600097    13934.0\n",
      "1   tamil-nadu  600119   131500.0\n",
      "2  maharashtra  400072   261515.0\n",
      "3   tamil-nadu  641654   296818.0\n",
      "4   tamil-nadu  641603   303843.0\n",
      "5   tamil-nadu  600014   320013.0\n",
      "6   tamil-nadu  641605   322254.0\n",
      "7   tamil-nadu  600044   325002.0\n",
      "8   tamil-nadu  641687   428456.0\n",
      "9  maharashtra  401209   748197.0\n"
     ]
    }
   ],
   "source": [
    "#4.Identify the 10 Pincodes that contribute the least to the user base in high-performing states like Maharashtra or Tamilnamdu.\n",
    "query = text(\"\"\"\n",
    "    SELECT \"State\", \"Pincode\", \n",
    "           SUM(\"Registered_User\") AS user_base\n",
    "    FROM top_user_pincode\n",
    "    WHERE \"State\" = 'tamil-nadu' OR \"State\" = 'maharashtra'\n",
    "    GROUP BY \"State\", \"Pincode\"\n",
    "    ORDER BY user_base ASC\n",
    "    LIMIT 10;\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    df_low_pincodes = pd.read_sql(query, conn)\n",
    "\n",
    "print(df_low_pincodes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
